---
title: "fahb simulation study"
format: html
editor: visual
---

## Introduction

This document records the design and analysis of a simulation study comparing methods for making progression decisions based on internal pilot recruitment data.

## Variables and paramerters

Using the syntax of the code, we have the following design variables:

-   `m` - the number of sites to open over the full trial
-   `int_t` - the timing of the pilot interim analysis, expressed as a proportion of the expected time to recruit to target
-   `target_n` - the target sample size which will lead to recruitment stopping

We also have some model parameters:

-   `beta_0` and `sqrt(var_l)` - parameters for the log-normal distribution of the site recruitment rates
-   `setup_r` - the setup rate for sites

Becuase we have a Bayesian model, the parameters to vary in a simulation study are actually the hyper-parameters describing the priors for the three substantive parameters above. We have:

-   `beta_m` and `beta_s` - parameters of the normal prior on `beta_0`
-   `v_df` and `v_c` - parameters of the gamma prior on `sqrt(var_l)`
-   `setup_r_a` and `setup_r_b` - parameters of the gamma prior on `setup_r`

## Scenarios

We will define scenariuos by taking low or high values for:

-   The design parameters;
-   The expected prior values of the three substantive model parameters; and
-   An overall level of uncertainty in all three prior distributions.

For `m`, we will use 10 (low) or 30 (high).

For `int_t` we will use 0.2 (low) or 0.5 (high).

For `target_n` we will use 352 (low) or 788 (hgih). These correspond to total numbers of patients needed to detect an effect of 0.3 or 0.2 respectively, with a two-sided type I error rate of 0.05 and a power of 0.8.

For the expectation of `beta_0` we will use 6 (low) or 20 (high) patients per site per year.

For the expectation of `sqrt((var_l)` we will use 1 (low) or 3 (high).

For the expectation of `setup_r` we will use 5 (low) and 15 (high) sites per year.

For each of these parameters and each of these settings, we want a version with low prior uncertainty and one with high prior uncertainty. First, `beta_0`:

```{r}
# Low expectation, low variance
beta_m <- 1.79; beta_s <- sqrt(2*(log(6) - beta_m))
beta_s
exp(beta_m + beta_s^2/2); sqrt(exp(beta_s^2 + 2)*sqrt(exp(beta_s^2) - 1))

# Low expectation, high variance
beta_m <- 1.75; beta_s <- sqrt(2*(log(6) - beta_m))
beta_s
exp(beta_m + beta_s^2/2); sqrt(exp(beta_s^2 + 2)*sqrt(exp(beta_s^2) - 1))

# High expectation, low variance
beta_m <- 2.994; beta_s <- sqrt(2*(log(20) - beta_m))
beta_s
exp(beta_m + beta_s^2/2); sqrt(exp(beta_s^2 + 2)*sqrt(exp(beta_s^2) - 1))

# Low expectation, high variance
beta_m <- 2.954; beta_s <- sqrt(2*(log(20) - beta_m))
beta_s
exp(beta_m + beta_s^2/2); sqrt(exp(beta_s^2 + 2)*sqrt(exp(beta_s^2) - 1))
```

Now `sqrt(var_l)`:

```{r}
library(extraDistr)

# Low expectation (0.05), low variance
v_sh <- 100; v_r <- v_sh/0.05
v_r
v_sh/v_r; sqrt(v_sh/(v_r^2))

# Low expectation, high variance
v_sh <- 5; v_r <- v_sh/0.05
v_r
v_sh/v_r; sqrt(v_sh/(v_r^2))

# High expectation (0.3), low variance
v_sh <- 500; v_r <- v_sh/0.3
v_r
v_sh/v_r; sqrt(v_sh/(v_r^2))

# High expectation, high variance
v_sh <- 30; v_r <- v_sh/0.3
v_r
v_sh/v_r; sqrt(v_sh/(v_r^2))
```

And finally, `setup_r`:

```{r}
# Low expectation, low variance
setup_r_a <- 200; setup_r_b <- setup_r_a/5
setup_r_b
setup_r_a/setup_r_b; sqrt(setup_r_a/(setup_r_b^2))

# Low expectation, high variance
setup_r_a <- 10; setup_r_b <- setup_r_a/5
setup_r_b
setup_r_a/setup_r_b; sqrt(setup_r_a/(setup_r_b^2))

# High expectation, low variance
setup_r_a <- 1800; setup_r_b <- setup_r_a/15
setup_r_b
setup_r_a/setup_r_b; sqrt(setup_r_a/(setup_r_b^2))

# High expectation, high variance
setup_r_a <- 90; setup_r_b <- setup_r_a/15
setup_r_b
setup_r_a/setup_r_b; sqrt(setup_r_a/(setup_r_b^2))
```

Now we put all these variations into a .csv file to be read in during the batch. Note we will replicate each scenario 10 times, running 10\^4 simulations in each component.

```{r}
m <- c(10, 30)
int_t <- c(0.2, 0.5)
target_n <- c(352,  788)

rec_rate <- c(1,2)
rec_v <- c(1,2)
setup_r <- c(1,2)

# First, make a matrix of values for the low prior uncertainty case

low_unc <- expand.grid(m, int_t, target_n, rec_rate, rec_v, setup_r)
low_unc$beta_m <- c(1.79, 2.994)[low_unc[,4]]
low_unc$beta_s <- c(0.0593, 0.0588)[low_unc[,4]]
low_unc$v_sh <- c(100, 500)[low_unc[,5]]
low_unc$v_r <- c(2000, 1667)[low_unc[,5]]
low_unc$setup_r_a <- c(200, 1800)[low_unc[,6]]
low_unc$setup_r_b <- c(40, 120)[low_unc[,6]]

low_unc <- low_unc[,c(1:3, 7:12)]

# Similarly for high uncertainty

hi_unc <- expand.grid(m, int_t, target_n, rec_rate, rec_v, setup_r)
hi_unc$beta_m <- c(1.75, 2.954)[hi_unc[,4]]
hi_unc$beta_s <- c(0.2890, 0.2889)[hi_unc[,4]]
hi_unc$v_sh <- c(5, 30)[hi_unc[,5]]
hi_unc$v_r <- c(100, 100)[hi_unc[,5]]
hi_unc$setup_r_a <- c(10, 90)[hi_unc[,6]]
hi_unc$setup_r_b <- c(2, 6)[hi_unc[,6]]

hi_unc <- hi_unc[,c(1:3, 7:12)]

scenarios <- rbind(low_unc, hi_unc)
scenarios <- cbind(1:nrow(scenarios), scenarios)

# Replicate each scanrio 10 times to split across HPC
scenarios <- scenarios[rep(1:nrow(scenarios), each = 10),]
scenarios$part <- rep(1:10, 128)
scenarios <- scenarios[, c(1, 11, 2:10)]
names(scenarios)[1:5] <- c("id", "part", "m", "int_t", "target_n")

#write.csv(scenarios, file = paste0("R/scenarios.csv"), row.names = FALSE)
```

Each scenario will have a different expected time to recruit, which we will use to set our feasibility threshold - at 1.2 times this expectation.

```{r}
exp_rec_time <- function(sce){

  m <- sce[3]; target_n <- sce[5]
  beta_m <- sce[6]; beta_s <- sce[7]
  setup_r_a <- sce[10]; setup_r_b <- sce[11]
  
  # Expected rate of recruitment after all sites open
  final_rate <- exp(beta_m + beta_s^2/2)*m
  # Expected time until all sites open
  all_open <- m/(setup_r_a/setup_r_b)
  # Expected number recruited when all sites open
  n_0 <- final_rate*all_open/2
  if(n_0 >= target_n){
    exp_time <- sqrt(2*target_n*all_open/final_rate)
  } else {
    exp_time <- (target_n - (n_0 - final_rate*all_open))/final_rate
  }
  return(exp_time)
}

scenarios$exp_t <- apply(scenarios, 1, exp_rec_time)
scenarios$thr <- 1.2*scenarios$exp_t

#write.csv(scenarios, file = paste0("R/scenarios.csv"), row.names = FALSE)
```

Plot the four priors for each of the three parameters - for each, a low and high mean and a low and high uncertainty.

```{r}
N <- 10^5
df <- data.frame(y = c(exp(rnorm(N, 1.79, 0.0593)),
                       exp(rnorm(N, 1.75,0.2890)),
                       exp(rnorm(N, 2.994, 0.0588)),
                       exp(rnorm(N, 2.954, 0.2889))),
                 val = rep(c("low", "high"), each = 2*N),
                 unc = rep(rep(c("low", "high"), each = N), 2))

p1 <- ggplot(df, aes(y, fill = val, colour= unc)) + stat_density(alpha = 0.1) +
  xlim(c(0,30)) + xlab("Expected recruitment rate") + 
  theme_minimal()
```

```{r}
df <- data.frame(y = c(rgamma(N, 100, 2000),
                       rgamma(N, 5, 100),
                       rgamma(N, 500, 1667),
                       rgamma(N, 30, 100)),
                 val = rep(c("low", "high"), each = 2*N),
                 unc = rep(rep(c("low", "high"), each = N), 2))

p2 <- ggplot(df, aes(y, fill = val, colour= unc)) + stat_density(alpha = 0.1) +
  xlab("Standard deviation of recruitment rate") + 
  theme_minimal()
```

```{r}
df <- data.frame(y = c(rgamma(N, 200, 40),
                       rgamma(N, 10, 2),
                       rgamma(N, 1800, 120),
                       rgamma(N, 90, 6)),
                 val = rep(c("low", "high"), each = 2*N),
                 unc = rep(rep(c("low", "high"), each = N), 2))

p3 <- ggplot(df, aes(y, fill = val, colour= unc)) + stat_density(alpha = 0.1) +
  xlab("Site opening rate") + 
  theme_minimal()

p1 / p2 / p3 + plot_layout(guides = 'collect')

ggsave("priors.pdf", height=12, width=14, units="cm")
```

## Analysis

For every scenario, find the FPR/FNR curves for both the PC and Bayes approaches to analysis. This takes a bit of time (especially the MCO for the PC approach), so do it once and save the results.

```{r}
full_res <- NULL
for(i in 1:128){
  print(i)
  res_comp <- PC_OCs_curve(i)
  res_comp <- cbind(res_comp, Bayes_OCs_curve(i)[,2])
  res_comp <- cbind(i, res_comp)
  full_res <- rbind(full_res, res_comp)
}

# Note - we are getting a v. small proportions (max 0.5%) of NAs in the Bayesian
# mean predictions in a handful of scenarios

for(i in 1:128){
  full_res[full_res$sce == i, 7] <- Bayes_OCs_curve(i)[,2]
}

#saveRDS(full_res, "full_res.rds")
```


```{r}
full_res <- as.data.frame(readRDS("full_res.rds"))
names(full_res) <- c("sce", "fpr", "fnr_PC", "red_m", "red_n", "red_r", "fnr_B")
full_res$fnr_dif <- full_res$fnr_PC - full_res$fnr_B

ggplot(full_res, aes(x = fnr_dif)) + stat_density(alpha = 0.4) +
  xlab("Difference in optimal False Negative Rates") + 
  xlim(c(-0.025, 0.1)) +
  theme_minimal()

#ggsave("fnr_dif.pdf", height=9, width=14, units="cm")
```

Some numerical summaries:

```{r}
mean(full_res$fnr_dif)
quantile(full_res$fnr_dif, c(0.005, 0.995))
```

Look at redundancy in the optimal PC rules:

```{r}
colMeans(full_res[,4:6])
num_red <- full_res[,4] + full_res[,5] + full_res[,6]
mean(num_red == 0); mean(num_red == 1); mean(num_red == 2)
```
## Illustrative example

We will replace this with GUSTO, but as a placeholder and to work out the figures we will use scenario 126.

```{r}
sces <- read.csv("R/scenarios.csv")
sces[sces$id == 126,][1,]
```

So we have a trial expected to recruit to 788 within 2.3 years, with 30 sites and an interim analysis after 20% of the recruitment window has passed.

```{r}
full_res <- as.data.frame(readRDS("full_res.rds"))
names(full_res) <- c("sce", "fpr", "fnr_PC", "red_m", "red_n", "red_r", "fnr_B")
full_res$fnr_dif <- full_res$fnr_PC - full_res$fnr_B

sub <- full_res[full_res$sce == 126,]

df <- data.frame(fpr = rep(sub$fpr, 2),
                 fnr = c(sub$fnr_PC, sub$fnr_B),
                 t = rep(c("PC", "Bayes"), each = nrow(sub)))

ggplot(df, aes(fpr, fnr, colour = t)) + geom_point() +
  xlab("False Positive Rate") + ylab("False Negative Rate") +
  scale_colour_discrete(name = "Method") +
  theme_minimal()

#ggsave("ill_ex.pdf", height=9, width=14, units="cm")
```

Looking at a specific FPR:

```{r}
# Manually for now - need to re-run full analysis to keep the PC rule details
# 0.20 0.250052665 -0.117898543 18.07059981 15.695877 1 0 0
```

For GUSTO - target is 320 participants over 3 years from 20 sites.

Recruitment estimated at 13 per month once all sites are open - so 7.8 per site per year.

PC are at least 5 sites open and at least 30 participants recruited by 6 months.

If we assume a steady increase in recruitment rate as sites open, the above assumptions imply all sites will be open at 1.90 years into the study and so we get a site opening rate of 10.53 sites per year.

```{r}
beta_m <- 2; beta_s <- sqrt(2*(log(7.8) - beta_m))
beta_s
exp(beta_m + beta_s^2/2); sqrt(exp(beta_s^2 + 2)*sqrt(exp(beta_s^2) - 1))
hist(exp(rnorm(10^4, beta_m, beta_s)))

v_sh <- 30; v_r <- v_sh/0.3
v_r
v_sh/v_r; sqrt(v_sh/(v_r^2))
hist(rgamma(10^4, v_sh, rate = v_r))

beta <- rnorm(10^4, beta_m, beta_s)
sig <- rgamma(10^4, v_sh, rate = v_r)
lambdas <- exp(rnorm(10^4, beta, sig))
hist(lambdas)

setup_r_a <- 30; setup_r_b <- setup_r_a/10.53
setup_r_b
setup_r_a/setup_r_b; sqrt(setup_r_a/(setup_r_b^2))
hist(rgamma(10^4, setup_r_a, rate = setup_r_b))

gusto <- data.frame(id = 1,
                    part = 1:10,
                    m = 20,
                    int_t = 0.166,
                    target_n = 320,
                    beta_m = 2,
                    beta_s = 0.329,
                    v_sh = 30,
                    v_r = 100,
                    setup_r_a = 30,
                    setup_r_b = 2.85,
                    exp_t = 3,
                    thr = 1.2*3)


```
